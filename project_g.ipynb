{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.core.debugger import set_trace\n",
    "from torchtext.datasets import WikiText2\n",
    "import spacy\n",
    "import re\n",
    "import html\n",
    "from torchtext import data\n",
    "from spacy.symbols import ORTH\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as V\n",
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dogscats  dogscats.zip\twikitext-103  wikitext-2  wikitext-2-v1.zip\r\n"
     ]
    }
   ],
   "source": [
    "! ls data/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy_en  = spacy.load('en')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(x):\n",
    "    return [tok.text for tok in spacy_en.tokenizer(x)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize = tokenizer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train, valid, test = WikiText2.splits(TEXT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.datasets.language_modeling.WikiText2 at 0x7f8095f20710>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', '<eos>', ' ', '=', 'valkyria', 'chronicles', 'iii', '=', '<eos>', ' ']\n"
     ]
    }
   ],
   "source": [
    "for ex in train.examples:\n",
    "    print(ex.text[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train, vectors = \"fasttext.en.300d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torchtext.data.field.Field at 0x7f8095f205f8>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TEXT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_iter, valid_iter, test_iter = data.BPTTIterator.splits(\n",
    "    (train, valid, test),\n",
    "    batch_size=32,\n",
    "    bptt_len=30, # this is where we specify the sequence length\n",
    "    device = \"cuda\",\n",
    "    repeat=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "text\n",
      "tensor([[   12,  1934, 20015,    15,    29,    21, 11667,     2,     3,     3,\n",
      "         11200,    13,    56,    15,  1710,  4475,    10,    18,    10,    19,\n",
      "            15,     2,     2,    19,  1286,    75,    13, 26206,    19,     4,\n",
      "             3,     2],\n",
      "        [   13,    10,    30,    15,     4,     5,  4195,  3768,     2,    55,\n",
      "            26,    12,  3886,    15,     3,     5,     2,   140,   489,  2282,\n",
      "            15, 13895,    16,     2,     4,   655,    12,   532,     2,  1249,\n",
      "           149, 16441],\n",
      "        [   12,    32,     2,    15,  3062,    64,    27,    11,   121,    11,\n",
      "            20,    13,     4,    13,   129,    64,   107,  2991,  2613,    21,\n",
      "            15,     5,  7840, 19860,    13,   182,    13,    36,   939,     6,\n",
      "          3948,  1307],\n",
      "        [   15,   472, 10782,  1957,    22,   992,   207,    35,  3289,   194,\n",
      "            50,    12,   946,    12,     2,   462,     4,     5,     3,  5023,\n",
      "            13,     2,     9,     5,    12,   312,    12,    59,  1124,     8,\n",
      "            28,    10],\n",
      "        [ 3875,    22,  3276,    15,   340,  3934,     6,    45,   758,    33,\n",
      "            42,    15,    28,    13,  2820,    34, 25713,     2,     9,  2183,\n",
      "            12, 26694,  8517,     2,    13,    11,    13,   897,   338,     7,\n",
      "            51,  3678],\n",
      "        [ 3895,   323,     6,    15,     9,   219,     8,   880,  3109,  6238,\n",
      "           193,    15,  1700,    12,   492,   800,     3, 22355,    10,  5255,\n",
      "            13, 10653,    16,  7715,    12,     2,    12,    30,     3, 15396,\n",
      "           318,    82],\n",
      "        [  889,     4,     8,    15,  2006,    14,     7,    45,    10,    11,\n",
      "          1558,    15,    70,  3492,  4084,    25,    53,     5,     2,    22,\n",
      "            12,     9,  5418,     3,    15,   195,    15,     2,     9,    14,\n",
      "          1313,  2088],\n",
      "        [   15,    33,     7,    13,     3,   205,    26,  2077,     2,  7644,\n",
      "             3,    82,  9135,    11,     9,   991,  4184, 22901,  1149,   406,\n",
      "            16,    14,    33,    62,    15,     5,    15,   137,  2783,  2817,\n",
      "         23290,    11],\n",
      "        [   13,    28, 23500,    12,   115,     5,     3,     5,   156,     4,\n",
      "          5423, 10899,     3,     2,     2,  2359,  6437,    33,     5,     3,\n",
      "             2,  8568,    96,   498,    15, 13915,    15,   158,  4352,    11,\n",
      "             4,     2],\n",
      "        [   12,    14,     4,    13,     3,   698,  1076,     2,    34,   245,\n",
      "            50,     9,  5995,   468,  2820,     3,     3,    16,   489,    37,\n",
      "         13294, 15896,    10,    70,  1414,    18,  1258,     4,    19,  5247,\n",
      "          1154, 18848],\n",
      "        [   13,   131,   572,    12,   292,     4,    28,    76,  2685,    11,\n",
      "          4206,  3867,     9,     5,  1608,   153,  1926,    17,  2613,    31,\n",
      "            16,     5,     2,  2780,  3434,  8430,     9,   175,     2,     2,\n",
      "          6728,     5],\n",
      "        [   12,    18,   238,    13,    46,    40,    46,     4,   396,  3876,\n",
      "            11,    15,  4817,     2,  1220, 25501,     2, 10304,    52,     2,\n",
      "            42,     2,   559,    44,  3205,    18,  6474,    71,   902, 17760,\n",
      "           506,     2],\n",
      "        [20060,   133,  5912,    12,     6,    28,   760,    13,    11,  3490,\n",
      "             6,    15,    10,   263,     4,   224,   648,    16,  3954,    68,\n",
      "          1892,    42,  1277,     2,    15, 12645,   893, 13486,  1124,  7714,\n",
      "         26483,  1509],\n",
      "        [   93,     6,    23,    15,     8,   145,   131,    12,    93,  6662,\n",
      "             8,    15,    95,   903,  1710,  2578,  1056,     4,     5,   252,\n",
      "            19,   107,  1061,  1335,    15,    11,    15,    34,   338,    77,\n",
      "             9,   216],\n",
      "        [ 3875,     8,     2,    15,     7,   113,    11,    13,   770,  6952,\n",
      "             7,    13,   214,     3,  1424,    97,     5,   440,  4379,  6173,\n",
      "           279,   118,     3,   135,    15,   643,    15,   897,    55,    11,\n",
      "         18305,    10],\n",
      "        [   98,     7,  1453,    15,    77,  9758,    32,    12,     9,     3,\n",
      "             3,    12,     4,     2,    17,    22,     2,     3,     4,  6103,\n",
      "           360,    37,  1201, 22289,    13,  1012,    15,    30,    10,   687,\n",
      "            23,  2170],\n",
      "        [   52,     4,   372,    15,    30,  2905,    63,    13,  3504,  2246,\n",
      "             2,    13,    10,  4457,  1041,  3197, 11018,     2,    10, 11206,\n",
      "             3,   638,     4, 10649,    12,     2,    13,  1463,   262,    87,\n",
      "         22483,     4],\n",
      "        [    6,   502,     5,  1299,    32,  2494,  1507,    12,  2167,    22,\n",
      "          1810,    12,     2, 10792,    10,   331,     5,     6,   489,     9,\n",
      "           306,     2,   422,   135,    13,  1843,    12, 14883,    55,   840,\n",
      "             6,    14],\n",
      "        [    8,  2627,     2,   459,  5322,   924,    19,    15,     3,   508,\n",
      "         11132,    67,   105,    27,  2603,    10,     2,     8,  2613,  9127,\n",
      "            10,   114,  1322,    17,    12,    19,    13,     3,   478,  1073,\n",
      "             8,  1509],\n",
      "        [    7,    22,  2171,    15,    43,   702,     2,   274,   440,    16,\n",
      "         13627,  1569,    95,  1234,    66,    14, 11175,     7,   314,  1916,\n",
      "             2, 20370,  5475,   535,    10, 21244,    12,    81,     4,     4,\n",
      "             7,  3381],\n",
      "        [ 3895,   281,   491,    15,    30,   104,  2168,  1767, 11360,   631,\n",
      "            27,    10,   301,    52,     2,  4280,    18,   339,     3, 10775,\n",
      "           137,    35, 10045,    21,  1889,     3,  3671,  2670,     2,    10,\n",
      "             3,  1755],\n",
      "        [   27,     3,  5970,    15,    32,     3,  2200,  8662,    19,    16,\n",
      "             6,     2,    55,     6, 27922,     9,   349,     3,  2660,     4,\n",
      "           158, 25450,   932,   141,     3,   101,  9698,  3401,  5497,  5815,\n",
      "           129,    52],\n",
      "        [  789, 22846,   659,    15,   290,    37,     4,    15,  1021,   119,\n",
      "             8,  4018,  1234,     8,  9504,    33,  1501,   180,    28,   517,\n",
      "            19,    30,    40,     4,    14,  1902,    30,  6046,   372,     3,\n",
      "             6,    13],\n",
      "        [   52,  8698,    17,    13,     4,     3,    33,    13,  3127,    68,\n",
      "             7,    17,    28,     7,  1818,  3788,     4,  5277,   797,     2,\n",
      "             2, 27795,    11,  2720,  1414,   310,     2,   840,     5,    14,\n",
      "             8,    12],\n",
      "        [28868,  5936,    51,    12,    32,    67,    82,    12,  1956,     9,\n",
      "            26,    42,   573,     6,     3,  1237,    13,    11,    20,  7267,\n",
      "          1239,    22,     2,   144,  3434,    11,  3924,   138,    16, 17909,\n",
      "             7,    13],\n",
      "        [    3,     3,  4367,    13,   176,   573,  3773,    13,     9,   924,\n",
      "             4,   165,     4,     8,    24, 13133,    12,    32,    14,   496,\n",
      "           891, 18772,   406,    11,  3205,     2,  4726,   448,  9813,  8964,\n",
      "           151,    12],\n",
      "        [ 6216,   260,     4,    12,   548,    11,    11,    12,  7994,    11,\n",
      "             2,    25,     2,     7,     2,  9588,    10,  6358,  1370,  1859,\n",
      "             4,     6,    22,  1875,    17,   474,     5,    34,    16,  1086,\n",
      "             6,    15],\n",
      "        [    4,   812,    25,    75,   564,     2,   631,   274,    23,    38,\n",
      "          4628,     2,   185,    26,  2525,   873, 18238,  4842,   987,    83,\n",
      "            24,     8,    64,     6,   458,  4839,   934,  2465,   577,    14,\n",
      "             8,    15],\n",
      "        [ 3875,   147,  1939,    31,   148,  3041,    11,  1767,   194,   312,\n",
      "            23,   103,     5,    17,     5,    11,     3,    31,    10,     3,\n",
      "            50,     7, 17040,     8,     9,     5,   936,    70,    31,  3640,\n",
      "             7,    15],\n",
      "        [    5,   686,    62,     2,     3,  1185,  1653,  8662,    49,     6,\n",
      "             2,    45,  1054,   287,   876,    38,    67,     2,    14,     9,\n",
      "          8443,    27,     6,     7,    14,  7924,  3077,  3595,   127,   434,\n",
      "             3,   510]], device='cuda:0')\n",
      "target\n",
      "tensor([[   13,    10,    30,    15,     4,     5,  4195,  3768,     2,    55,\n",
      "            26,    12,  3886,    15,     3,     5,     2,   140,   489,  2282,\n",
      "            15, 13895,    16,     2,     4,   655,    12,   532,     2,  1249,\n",
      "           149, 16441],\n",
      "        [   12,    32,     2,    15,  3062,    64,    27,    11,   121,    11,\n",
      "            20,    13,     4,    13,   129,    64,   107,  2991,  2613,    21,\n",
      "            15,     5,  7840, 19860,    13,   182,    13,    36,   939,     6,\n",
      "          3948,  1307],\n",
      "        [   15,   472, 10782,  1957,    22,   992,   207,    35,  3289,   194,\n",
      "            50,    12,   946,    12,     2,   462,     4,     5,     3,  5023,\n",
      "            13,     2,     9,     5,    12,   312,    12,    59,  1124,     8,\n",
      "            28,    10],\n",
      "        [ 3875,    22,  3276,    15,   340,  3934,     6,    45,   758,    33,\n",
      "            42,    15,    28,    13,  2820,    34, 25713,     2,     9,  2183,\n",
      "            12, 26694,  8517,     2,    13,    11,    13,   897,   338,     7,\n",
      "            51,  3678],\n",
      "        [ 3895,   323,     6,    15,     9,   219,     8,   880,  3109,  6238,\n",
      "           193,    15,  1700,    12,   492,   800,     3, 22355,    10,  5255,\n",
      "            13, 10653,    16,  7715,    12,     2,    12,    30,     3, 15396,\n",
      "           318,    82],\n",
      "        [  889,     4,     8,    15,  2006,    14,     7,    45,    10,    11,\n",
      "          1558,    15,    70,  3492,  4084,    25,    53,     5,     2,    22,\n",
      "            12,     9,  5418,     3,    15,   195,    15,     2,     9,    14,\n",
      "          1313,  2088],\n",
      "        [   15,    33,     7,    13,     3,   205,    26,  2077,     2,  7644,\n",
      "             3,    82,  9135,    11,     9,   991,  4184, 22901,  1149,   406,\n",
      "            16,    14,    33,    62,    15,     5,    15,   137,  2783,  2817,\n",
      "         23290,    11],\n",
      "        [   13,    28, 23500,    12,   115,     5,     3,     5,   156,     4,\n",
      "          5423, 10899,     3,     2,     2,  2359,  6437,    33,     5,     3,\n",
      "             2,  8568,    96,   498,    15, 13915,    15,   158,  4352,    11,\n",
      "             4,     2],\n",
      "        [   12,    14,     4,    13,     3,   698,  1076,     2,    34,   245,\n",
      "            50,     9,  5995,   468,  2820,     3,     3,    16,   489,    37,\n",
      "         13294, 15896,    10,    70,  1414,    18,  1258,     4,    19,  5247,\n",
      "          1154, 18848],\n",
      "        [   13,   131,   572,    12,   292,     4,    28,    76,  2685,    11,\n",
      "          4206,  3867,     9,     5,  1608,   153,  1926,    17,  2613,    31,\n",
      "            16,     5,     2,  2780,  3434,  8430,     9,   175,     2,     2,\n",
      "          6728,     5],\n",
      "        [   12,    18,   238,    13,    46,    40,    46,     4,   396,  3876,\n",
      "            11,    15,  4817,     2,  1220, 25501,     2, 10304,    52,     2,\n",
      "            42,     2,   559,    44,  3205,    18,  6474,    71,   902, 17760,\n",
      "           506,     2],\n",
      "        [20060,   133,  5912,    12,     6,    28,   760,    13,    11,  3490,\n",
      "             6,    15,    10,   263,     4,   224,   648,    16,  3954,    68,\n",
      "          1892,    42,  1277,     2,    15, 12645,   893, 13486,  1124,  7714,\n",
      "         26483,  1509],\n",
      "        [   93,     6,    23,    15,     8,   145,   131,    12,    93,  6662,\n",
      "             8,    15,    95,   903,  1710,  2578,  1056,     4,     5,   252,\n",
      "            19,   107,  1061,  1335,    15,    11,    15,    34,   338,    77,\n",
      "             9,   216],\n",
      "        [ 3875,     8,     2,    15,     7,   113,    11,    13,   770,  6952,\n",
      "             7,    13,   214,     3,  1424,    97,     5,   440,  4379,  6173,\n",
      "           279,   118,     3,   135,    15,   643,    15,   897,    55,    11,\n",
      "         18305,    10],\n",
      "        [   98,     7,  1453,    15,    77,  9758,    32,    12,     9,     3,\n",
      "             3,    12,     4,     2,    17,    22,     2,     3,     4,  6103,\n",
      "           360,    37,  1201, 22289,    13,  1012,    15,    30,    10,   687,\n",
      "            23,  2170],\n",
      "        [   52,     4,   372,    15,    30,  2905,    63,    13,  3504,  2246,\n",
      "             2,    13,    10,  4457,  1041,  3197, 11018,     2,    10, 11206,\n",
      "             3,   638,     4, 10649,    12,     2,    13,  1463,   262,    87,\n",
      "         22483,     4],\n",
      "        [    6,   502,     5,  1299,    32,  2494,  1507,    12,  2167,    22,\n",
      "          1810,    12,     2, 10792,    10,   331,     5,     6,   489,     9,\n",
      "           306,     2,   422,   135,    13,  1843,    12, 14883,    55,   840,\n",
      "             6,    14],\n",
      "        [    8,  2627,     2,   459,  5322,   924,    19,    15,     3,   508,\n",
      "         11132,    67,   105,    27,  2603,    10,     2,     8,  2613,  9127,\n",
      "            10,   114,  1322,    17,    12,    19,    13,     3,   478,  1073,\n",
      "             8,  1509],\n",
      "        [    7,    22,  2171,    15,    43,   702,     2,   274,   440,    16,\n",
      "         13627,  1569,    95,  1234,    66,    14, 11175,     7,   314,  1916,\n",
      "             2, 20370,  5475,   535,    10, 21244,    12,    81,     4,     4,\n",
      "             7,  3381],\n",
      "        [ 3895,   281,   491,    15,    30,   104,  2168,  1767, 11360,   631,\n",
      "            27,    10,   301,    52,     2,  4280,    18,   339,     3, 10775,\n",
      "           137,    35, 10045,    21,  1889,     3,  3671,  2670,     2,    10,\n",
      "             3,  1755],\n",
      "        [   27,     3,  5970,    15,    32,     3,  2200,  8662,    19,    16,\n",
      "             6,     2,    55,     6, 27922,     9,   349,     3,  2660,     4,\n",
      "           158, 25450,   932,   141,     3,   101,  9698,  3401,  5497,  5815,\n",
      "           129,    52],\n",
      "        [  789, 22846,   659,    15,   290,    37,     4,    15,  1021,   119,\n",
      "             8,  4018,  1234,     8,  9504,    33,  1501,   180,    28,   517,\n",
      "            19,    30,    40,     4,    14,  1902,    30,  6046,   372,     3,\n",
      "             6,    13],\n",
      "        [   52,  8698,    17,    13,     4,     3,    33,    13,  3127,    68,\n",
      "             7,    17,    28,     7,  1818,  3788,     4,  5277,   797,     2,\n",
      "             2, 27795,    11,  2720,  1414,   310,     2,   840,     5,    14,\n",
      "             8,    12],\n",
      "        [28868,  5936,    51,    12,    32,    67,    82,    12,  1956,     9,\n",
      "            26,    42,   573,     6,     3,  1237,    13,    11,    20,  7267,\n",
      "          1239,    22,     2,   144,  3434,    11,  3924,   138,    16, 17909,\n",
      "             7,    13],\n",
      "        [    3,     3,  4367,    13,   176,   573,  3773,    13,     9,   924,\n",
      "             4,   165,     4,     8,    24, 13133,    12,    32,    14,   496,\n",
      "           891, 18772,   406,    11,  3205,     2,  4726,   448,  9813,  8964,\n",
      "           151,    12],\n",
      "        [ 6216,   260,     4,    12,   548,    11,    11,    12,  7994,    11,\n",
      "             2,    25,     2,     7,     2,  9588,    10,  6358,  1370,  1859,\n",
      "             4,     6,    22,  1875,    17,   474,     5,    34,    16,  1086,\n",
      "             6,    15],\n",
      "        [    4,   812,    25,    75,   564,     2,   631,   274,    23,    38,\n",
      "          4628,     2,   185,    26,  2525,   873, 18238,  4842,   987,    83,\n",
      "            24,     8,    64,     6,   458,  4839,   934,  2465,   577,    14,\n",
      "             8,    15],\n",
      "        [ 3875,   147,  1939,    31,   148,  3041,    11,  1767,   194,   312,\n",
      "            23,   103,     5,    17,     5,    11,     3,    31,    10,     3,\n",
      "            50,     7, 17040,     8,     9,     5,   936,    70,    31,  3640,\n",
      "             7,    15],\n",
      "        [    5,   686,    62,     2,     3,  1185,  1653,  8662,    49,     6,\n",
      "             2,    45,  1054,   287,   876,    38,    67,     2,    14,     9,\n",
      "          8443,    27,     6,     7,    14,  7924,  3077,  3595,   127,   434,\n",
      "             3,   510],\n",
      "        [    2,    20,    17, 14944,  2121,   992,     3,    28,   157,     8,\n",
      "          5170,  8107,  1753,    25,  2500,  1137,    33,     6,  1621,    10,\n",
      "          2333,  2929,     8,     2,  1414,     9,    10,   442,  8701,    24,\n",
      "            37, 10592]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "for batch in train_iter:\n",
    "    print(\"text\")\n",
    "    print(batch.text.data)\n",
    "    print(\"target\")\n",
    "    print(batch.target.data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   12,    13,    12,    15,  3875,  3895,   889,    15,    13,    12,\n",
       "           13,    12, 20060,    93,  3875,    98,    52,     6,     8,     7,\n",
       "         3895,    27,   789,    52, 28868,     3,  6216,     4,  3875,     5],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.text.data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([   13,    12,    15,  3875,  3895,   889,    15,    13,    12,    13,\n",
       "           12, 20060,    93,  3875,    98,    52,     6,     8,     7,  3895,\n",
       "           27,   789,    52, 28868,     3,  6216,     4,  3875,     5,     2],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.target.data[:,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LanguageModel(nn.Module):\n",
    "    def __init__(self, ntoken, ninp,\n",
    "                 nhid, nlayers, bsz,\n",
    "                 dropout=0.5):\n",
    "        super(LanguageModel, self).__init__()\n",
    "        self.nhid, self.nlayers, self.bsz = nhid, nlayers, bsz\n",
    "        self.drop = nn.Dropout(dropout)\n",
    "        self.encoder = nn.Embedding(ntoken, ninp)\n",
    "        self.rnn = nn.LSTM(ninp, nhid, nlayers, dropout=dropout)\n",
    "        self.decoder = nn.Linear(nhid,ntoken)\n",
    "\n",
    "        self.init_weights()\n",
    "        self.hidden = self.init_hidden(bsz)\n",
    "        \n",
    "    def init_weights(self):\n",
    "        initrange = 0.1\n",
    "        self.encoder.weight.data.uniform_(-initrange, initrange)\n",
    "        self.decoder.bias.data.fill_(0)\n",
    "        self.decoder.weight.data.uniform_(-initrange, initrange)\n",
    " \n",
    "    def forward(self, input):\n",
    "        emb = self.drop(self.encoder(input))\n",
    "        output, self.hidden = self.rnn(emb, self.hidden)\n",
    "        output = self.drop(output)\n",
    "        decoded = self.decoder(output.view(output.size(0)*output.size(1), output.size(2)))\n",
    "        return decoded.view(output.size(0), output.size(1), decoded.size(1))\n",
    " \n",
    "    def init_hidden(self, bsz):\n",
    "        weight = next(self.parameters()).data\n",
    "        return (torch.tensor(weight.new(self.nlayers, bsz, self.nhid).zero_().cuda()),\n",
    "                torch.tensor(weight.new(self.nlayers, bsz, self.nhid).zero_()).cuda())\n",
    "  \n",
    "    def reset_history(self):\n",
    "        self.hidden = tuple(torch.tensor(v.data) for v in self.hidden)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/torch/nn/modules/rnn.py:38: UserWarning: dropout option adds dropout after all but last recurrent layer, so non-zero dropout expects num_layers greater than 1, but got dropout=0.5 and num_layers=1\n",
      "  \"num_layers={}\".format(dropout, num_layers))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LanguageModel(\n",
       "  (drop): Dropout(p=0.5)\n",
       "  (encoder): Embedding(28870, 300)\n",
       "  (rnn): LSTM(300, 200, dropout=0.5)\n",
       "  (decoder): Linear(in_features=200, out_features=28870, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_matrix = TEXT.vocab.vectors\n",
    "model = LanguageModel(weight_matrix.size(0),\n",
    "weight_matrix.size(1), 200, 1, 32)\n",
    "model.encoder.weight.data.copy_(weight_matrix)\n",
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr = 1e-3, betas=(0.9,0.999))\n",
    "n_tokens = weight_matrix.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "def train_epoch(epoch):\n",
    "    epoch_loss = 0\n",
    "    for batch in tqdm(train_iter):\n",
    "        model.reset_history()\n",
    "    \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        text, targets = batch.text, batch.target\n",
    "        prediction = model(text)\n",
    "        loss = criterion(prediction.view(-1, n_tokens), targets.view(-1))\n",
    "        loss.backward()\n",
    "        \n",
    "        optimizer.step()\n",
    "        \n",
    "        batch_loss = loss.item() * prediction.size(0) * prediction.size(1)\n",
    "        \n",
    "        batch_loss /= len(train.examples[0].text)\n",
    "        \n",
    "        epoch_loss += batch_loss\n",
    "        \n",
    "\n",
    "    val_loss = 0\n",
    "    for batch in valid_iter:\n",
    "        model.reset_history()\n",
    "        text, targets = batch.text, batch.target\n",
    "        prediction = model(text)\n",
    "        loss = criterion(prediction.view(-1, n_tokens), targets.view(-1))\n",
    "        batch_loss = loss.item() * text.size(0)\n",
    "        batch_loss /= len(valid.examples[0].text) \n",
    "        val_loss += batch_loss\n",
    "        \n",
    "        \n",
    "    print('Epoch: {}, Training Loss: {:.4f}, Validation Loss: {:.4f}'.format(epoch, epoch_loss, val_loss))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/2330 [00:00<?, ?it/s]\u001b[A\n",
      "  0%|          | 1/2330 [00:00<19:06,  2.03it/s]\u001b[A\n",
      "  0%|          | 6/2330 [00:00<03:56,  9.81it/s]\u001b[A\n",
      "  0%|          | 11/2330 [00:00<02:34, 15.01it/s]\u001b[A\n",
      "  1%|          | 15/2330 [00:00<02:13, 17.38it/s]\u001b[A\n",
      "  1%|          | 20/2330 [00:00<01:53, 20.32it/s]\u001b[A\n",
      "  1%|          | 25/2330 [00:01<01:42, 22.60it/s]\u001b[A\n",
      "  1%|▏         | 30/2330 [00:01<01:34, 24.42it/s]\u001b[A\n",
      "Exception in thread Thread-10:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/paperspace/anaconda3/envs/fastai/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n",
      "100%|██████████| 2330/2330 [00:56<00:00, 40.96it/s]\n",
      "  0%|          | 0/2330 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 5.3230, Validation Loss: 0.1537\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2330/2330 [00:57<00:00, 40.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 5.2084, Validation Loss: 0.1515\n"
     ]
    }
   ],
   "source": [
    "for i in range(2):\n",
    "    train_epoch(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2330/2330 [00:56<00:00, 41.02it/s]\n",
      "  0%|          | 0/2330 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Training Loss: 5.1372, Validation Loss: 0.1505\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2330/2330 [00:57<00:00, 40.82it/s]\n",
      "  0%|          | 0/2330 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 1, Training Loss: 5.0868, Validation Loss: 0.1498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2330/2330 [00:57<00:00, 40.87it/s]\n",
      "  0%|          | 0/2330 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 2, Training Loss: 5.0499, Validation Loss: 0.1494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2330/2330 [00:56<00:00, 40.89it/s]\n",
      "  0%|          | 0/2330 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 3, Training Loss: 5.0243, Validation Loss: 0.1491\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2330/2330 [00:58<00:00, 39.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 4, Training Loss: 5.0054, Validation Loss: 0.1490\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    train_epoch(i)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "for i in range(2):\n",
    "    train_epoch(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
